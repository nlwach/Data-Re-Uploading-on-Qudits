{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QML model that learns to distinguish 5 different handwritten digits with 7 input dimensions\n",
    "\n",
    "This notebook uses Data ReUploading, to learn to classify 5 different handwirtten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from pennylane.optimize import AdamOptimizer, GradientDescentOptimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from scipy.sparse.linalg import expm\n",
    "from scipy.sparse import coo_matrix, csc_matrix, diags, identity\n",
    "\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, vmap, jit\n",
    "from jax import random\n",
    "\n",
    "import jax\n",
    "\n",
    "import scipy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import qutip as q\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again first define the spin matrices and the functions that act on a state. I will use a spin length of 4 which yields 9 states. I will use every second qudit state to label the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "l = 2 # spin length\n",
    "\n",
    "# let's put together spin matrices\n",
    "dim_qudit = 2*l+1\n",
    "qudit_range = np.arange(l, -(l+1),-1)\n",
    "\n",
    "Id  =  scipy.sparse.csc_matrix(identity(dim_qudit))\n",
    "Lx  =  scipy.sparse.csc_matrix(1/2*diags([np.sqrt([(l-m+1)*(l+m) for m in qudit_range[:-1]]), np.sqrt([(l+m+1)*(l-m) for m in qudit_range[1:]]) ], [-1, 1]))\n",
    "Lz  =  scipy.sparse.csc_matrix(diags([qudit_range], [0]))\n",
    "Lz2 = Lz.multiply(Lz)\n",
    "Lx2 = Lx.multiply(Lx)\n",
    "\n",
    "Lx = Lx.toarray()\n",
    "Lz = Lz.toarray()\n",
    "Lz2 = Lz2.toarray()\n",
    "\n",
    "\n",
    "Lx = jnp.array(Lx)\n",
    "Lz = jnp.array(Lz)\n",
    "Lz2 = jnp.array(Lz2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rx(psi, theta, conj=False):\n",
    "    Ux = jax.scipy.linalg.expm(-1j*theta*Lx)\n",
    "    psi = jnp.dot(Ux,psi)\n",
    "    return psi\n",
    "\n",
    "def Rz(psi, theta, conj=False):\n",
    "    Uz = jax.scipy.linalg.expm(-1j*theta*Lz)\n",
    "    psi = jnp.dot(Uz,psi)\n",
    "    return psi\n",
    "\n",
    "def Rz2(psi, theta, conj=False):\n",
    "    Uz2 = jax.scipy.linalg.expm(-1j*theta*Lz2)\n",
    "    psi = jnp.dot(Uz2,psi)\n",
    "    return psi\n",
    "\n",
    "def Initialization(psi :np.array, x1: float, x2: float, x3: float, x4: float, x5: float, x6, x7)-> np.array:\n",
    "    psi = Rz(psi, x1)\n",
    "    psi = Rx(psi, x2)\n",
    "    psi = Rz(psi, x3)\n",
    "    psi = Rx(psi, x4)\n",
    "    psi = Rz(psi, x5)\n",
    "    psi = Rz(psi, x6)\n",
    "    psi = Rx(psi, x7)\n",
    "    return psi\n",
    "\n",
    "\n",
    "def varaince_z(psi):\n",
    "    a = psi.T.conj()@Lz@psi\n",
    "    b = psi.T.conj()@Lz**2@psi\n",
    "    \n",
    "    return jnp.abs((b-a**2).real)\n",
    "\n",
    "def measure(psi):\n",
    "    prob = psi**2\n",
    "    measurement = np.random.choice(np.arange(len(state)), p=prob)\n",
    "    return measurement\n",
    "\n",
    "def expect(psi, oper):\n",
    "    return (psi.T.conj()@oper@psi).real\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_labels = [[i] for i in range(2*l+1)]\n",
    "used_labels = [[0], [1], [2], [3], [4]]\n",
    "\n",
    "def cost_circ(params, x, y, beta, return_ind, state_labels=used_labels):\n",
    "\n",
    "    loss_overlap = 0.0\n",
    "    loss_variance = 0.0\n",
    "    dm_labels = state_labels\n",
    "    \n",
    "    overlap, psi = circ(params, x, y, var_return=True)\n",
    "    loss_overlap +=(1 - overlap**2)\n",
    "\n",
    "    loss_variance += (varaince_z(psi)**2)*beta\n",
    "    loss = loss_overlap + loss_variance\n",
    "    if return_ind:\n",
    "        return loss, loss_variance, loss_overlap\n",
    "    return loss \n",
    "\n",
    "\n",
    "def circ(params, x, y, var_return=False):\n",
    "\n",
    "    psi = 1j*jnp.zeros(int(l*2+1))\n",
    "    #This is necessary since jnp arrays are immutable\n",
    "    psi = jax.ops.index_add(psi, 0, 1+1j*0)\n",
    "    \n",
    "    label = 1j*jnp.zeros(int(l*2+1))\n",
    "    #This is necessary since jnp arrays are immutable\n",
    "    label = jax.ops.index_add(label, y, 1+1j*0)\n",
    "\n",
    "    for i in range(0, len(params)-1):\n",
    "    \n",
    "        psi = Initialization(psi, x[0], x[1], x[2], x[3], x[4], x[5], x[6])\n",
    "    \n",
    "        psi = Rx(psi, params[i][0]) \n",
    "        \n",
    "        psi = Rz(psi, params[i][1])\n",
    "        \n",
    "        psi = Rx(psi, params[i][2]) \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        psi = Rz2(psi, params[i][3])\n",
    "\n",
    "    \n",
    "    psi = Rx(psi, params[i+1][0]) \n",
    "\n",
    "    psi = Rz(psi, params[i+1][1])\n",
    "\n",
    "    psi = Rx(psi, params[i+1][2]) \n",
    "        \n",
    "    \n",
    "    if var_return:\n",
    "        return  jnp.abs(jnp.dot(psi, label)), psi\n",
    "    return jnp.abs(jnp.dot(psi, label))\n",
    "\n",
    "\n",
    "def test(params, x, state_labels=used_labels):\n",
    "    \n",
    "    fidelities = jnp.array([circ(params, x, dm[0]) for dm in state_labels])\n",
    "    \n",
    "    best_fidel = jnp.argmax(fidelities)\n",
    "\n",
    "\n",
    "    return best_fidel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function is the following:\n",
    "\n",
    "\\begin{align}\n",
    "\\chi_f(\\theta)= \\sum_{i=1}^{m} (1- \\langle\\tilde{\\psi}_s|\\psi(\\vec{x}, \\vec{\\theta})\\rangle^2)\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "\n",
    "    score = y_true == y_pred\n",
    "    return score.sum() / len(y_true)\n",
    "\n",
    "\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batch_size):\n",
    "\n",
    "    for start_idx in range(0, inputs.shape[0] - batch_size + 1, batch_size):\n",
    "        idxs = slice(start_idx, start_idx + batch_size)\n",
    "        yield inputs[idxs], targets[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Th following functions are the jitted, vectorized versions of the cost and test function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def vmap_cost(params, X_batched, y_batched, beta=0.3):\n",
    "    return vmap(cost_circ,  in_axes=(None, 0, 0, None, None))(params, X_batched, y_batched, beta, False).sum()/len(X_batched)\n",
    "\n",
    "@jit\n",
    "def vmap_cost_ind(params, X_batched, y_batched, beta=0.3):\n",
    "    return vmap(cost_circ,  in_axes=(None, 0, 0, None, None))(params, X_batched, y_batched, beta, True)\n",
    "\n",
    "@jit\n",
    "def vmap_test(params, X_batched, state_labels):\n",
    "    return vmap(test,  in_axes=(None, 0, None))(params, X_batched, state_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the MNIST Handwritten dataset and pick 5 numbers out of this dataset. The numbers will correspond to the following labels:\n",
    "\n",
    "* 0 labelstate = $|4\\rangle$\n",
    "* 1 labelstate = $|0\\rangle$\n",
    "* 7 labelstate = $|1\\rangle$\n",
    "* 2 labelstate = $|3\\rangle$\n",
    "* 4 labelstate = $|2\\rangle$\n",
    "\n",
    "Since the numbers consist of $8 \\times 8$ pixels, and this is a little bit too much of input data we can use a Principle Component Analysis to reduce the dimensionality of the dataset to whatever size we want. I chose a dimensionality of $7$ in this notebook. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8)\n",
      "[0 1 2 3 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "zeros = digits[\"images\"][digits[\"target\"]==0]\n",
    "sevens = digits[\"images\"][digits[\"target\"]==7]\n",
    "ones = digits[\"images\"][digits[\"target\"]==1]\n",
    "twos = digits[\"images\"][digits[\"target\"]==2]\n",
    "fours = digits[\"images\"][digits[\"target\"]==4]\n",
    "\n",
    "zeros_y = digits[\"target\"][digits[\"target\"]==0]\n",
    "sevens_y = digits[\"target\"][digits[\"target\"]==7]\n",
    "ones_y = digits[\"target\"][digits[\"target\"]==1]\n",
    "twos_y = digits[\"target\"][digits[\"target\"]==2]\n",
    "fours_y = digits[\"target\"][digits[\"target\"]==4]\n",
    "\n",
    "data = digits[\"images\"]\n",
    "targets = digits[\"target\"]\n",
    "\n",
    "x_data = np.vstack((zeros, sevens))\n",
    "x_data = np.vstack((x_data, ones))\n",
    "x_data = np.vstack((x_data, twos))\n",
    "x_data = np.vstack((x_data, fours))\n",
    "\n",
    "y_data = np.hstack((zeros_y, sevens_y))\n",
    "y_data = np.hstack((y_data, ones_y))\n",
    "y_data = np.hstack((y_data, twos_y))\n",
    "y_data = np.hstack((y_data, fours_y))\n",
    "\n",
    "\n",
    "\n",
    "pca = PCA(n_components=7)\n",
    "print(data.shape)\n",
    "\n",
    "x_data = pca.fit_transform(x_data.reshape(x_data.shape[0], 64))\n",
    "\n",
    "x_data = x_data/np.amax(x_data)\n",
    "\n",
    "y_data[y_data==2] = 3\n",
    "y_data[y_data==4] = 2\n",
    "y_data[y_data==0] = 4\n",
    "y_data[y_data==1] = 0\n",
    "y_data[y_data==7] = 1\n",
    "\n",
    "\n",
    "print(np.unique(y_data))\n",
    "\n",
    "#used_labels = [[0], [2], [4], [6], [8]]\n",
    "\n",
    "np.unique(used_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need the gradient of the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_circ_grad = grad(vmap_cost, argnums=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything we need and can start learning. We first need to create the dataset and choose random parameters to start. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_data, y_data)\n",
    "used_labels_arr = np.array(used_labels)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "#layers = [2, 4, 6, 8, 10]\n",
    "layers = [3, 4, 5, 6, 7, 8, 9]\n",
    "iterations = 10\n",
    "#learning_Rates = [0.05, 0.01, 0.005, 0.001, 0.0005]\n",
    "\n",
    "\n",
    "beta = 0\n",
    "def training(j):\n",
    "    print(\"--------------------------------------\")\n",
    "    print(f\"Starting with {j} layers\")\n",
    "    for m in tqdm(range(7, iterations)):\n",
    "        \n",
    "        params = np.random.uniform(size=(j, 4))*np.pi/2\n",
    "        params[:, 3] = 0\n",
    "        \n",
    "        \n",
    "        losses = []\n",
    "        train_acc = []\n",
    "        param_list = []\n",
    "\n",
    "        epochs = 500\n",
    "\n",
    "        learning_rate = 0.005\n",
    "        opt = AdamOptimizer(learning_rate)\n",
    "        \n",
    "        train_x, test_x, train_y, test_y = train_test_split(x_data, y_data, shuffle=True, random_state=j*m+m)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            #print(\"--------------------------------------\")\n",
    "            #print(f\"Starting Epoch {i+1}, learning rate: {learning_rate:.2f}\")\n",
    "\n",
    "            for X_Batch, Y_Batch in iterate_minibatches(train_x, train_y, batch_size):\n",
    "                #print(X_Batch.shape, Y_Batch.shape)\n",
    "                params = opt.step(vmap_cost, params, grad_fn=cost_circ_grad, X_batched=X_Batch, y_batched=Y_Batch, beta=beta)\n",
    "                param_list.append(params)\n",
    "            pred_train = vmap_test(params, test_x, used_labels)\n",
    "            pred_train = np.array(pred_train)\n",
    "            for n, prediction in enumerate(pred_train):\n",
    "                pred_train[n] = used_labels_arr[prediction]\n",
    "            acc = accuracy_score(test_y, pred_train)\n",
    "            train_acc.append(acc)\n",
    "            loss = vmap_cost(params, train_x, train_y, beta)\n",
    "            losses.append(loss)\n",
    "            \n",
    "        np.save(f\"500e0-005lr_7Dim/params_{j}-layers-{m}.npy\", param_list)\n",
    "        np.save(f\"500e0-005lr_7Dim/loss_{j}-layers-{m}.npy\", losses)\n",
    "        np.save(f\"500e0-005lr_7Dim/acc_{j}-layers-{m}.npy\", train_acc)\n",
    "        np.save(f\"500e0-005lr_7Dim/pred_{j}-layers-{m}.npy\", pred_train)\n",
    "    return True\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Starting with 7 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [58:10<00:00, 1163.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "with Pool(1) as p:\n",
    "        print(p.map(training, layers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
